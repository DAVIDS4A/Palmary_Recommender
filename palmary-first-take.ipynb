{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"\nimport numpy as np\nimport pandas as pd\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.metrics.pairwise import linear_kernel\nfrom surprise import Dataset, Reader, KNNBasic, accuracy\nfrom surprise.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error\nfrom sklearn.metrics import precision_score, recall_score\n\n# Load your dataset with simulated ratings\ndf = pd.read_csv('/kaggle/input/bakery-with-simulatedrating/Bakery_with_SimulatedRating.csv')\n\nlabel_encoder = LabelEncoder()\nencoded_labels = label_encoder.fit_transform(df.DateTime)\ndf['DateTime'] = encoded_labels\n\nlabel_encoder = LabelEncoder()\nencoded_labels1 = label_encoder.fit_transform(df.Daypart)\ndf['Daypart'] = encoded_labels1\n\nlabel_encoder = LabelEncoder()\nencoded_labels2 = label_encoder.fit_transform(df.DayType)\ndf['DayType'] = encoded_labels2\n\n# Collaborative Filtering (using Surprise)\nreader = Reader(rating_scale=(1, 5))\ndata = Dataset.load_from_df(df[['TransactionNo', 'Items', 'SimulatedRating']], reader)\ntrainset, testset = train_test_split(data, test_size=0.2)\n\ncf_model = KNNBasic()\ncf_model.fit(trainset)\ncf_predictions = cf_model.test(testset)\n\n# Calculate MAE and RMSE for Collaborative Filtering\ncf_true_ratings = [testset[i][2] for i in range(len(testset))]\ncf_pred_ratings = [cf_predictions[i].est for i in range(len(cf_predictions))]\n\ncf_mae = mean_absolute_error(cf_true_ratings, cf_pred_ratings)\ncf_rmse = np.sqrt(mean_squared_error(cf_true_ratings, cf_pred_ratings))\n\nprint(f'Collaborative Filtering MAE: {cf_mae}')\nprint(f'Collaborative Filtering RMSE: {cf_rmse}')\n\n\n# Content-Based Filtering (using scikit-learn)\ntfidf_vectorizer = TfidfVectorizer(stop_words='english')\ntfidf_matrix = tfidf_vectorizer.fit_transform(df['Items'])\n\ncosine_sim = linear_kernel(tfidf_matrix, tfidf_matrix)\n\n# Function to get content-based recommendations for a given item\ndef get_content_based_recommendations(item_index):\n    sim_scores = list(enumerate(cosine_sim[item_index]))\n    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n    sim_scores = sim_scores[1:6]  # Top 5 similar items (excluding itself)\n    item_indices = [i[0] for i in sim_scores]\n    return df['Items'].iloc[item_indices]\n\n# Hybrid Recommendation System\ndef hybrid_recommendation(transaction_no):\n    # Assuming 'transaction_no' is a unique identifier for a transaction\n    # Get collaborative filtering recommendations for the given transaction\n    # f_top_n = get_cf_recommendations(transaction_no)\n\n    # Check if the transaction number exists in the dataset\n    if transaction_no not in df['TransactionNo'].values:\n        return \"Transaction not found.\"\n\n    # Find the item associated with the transaction (you may need to adapt this)\n    item_index = df[df['TransactionNo'] == transaction_no].index[0]\n    \n    # Check if item_index is within bounds\n    if item_index >= len(df):\n        return \"Item not found.\"\n\n    # Get content-based recommendations for the item\n    content_based_recommendations = get_content_based_recommendations(item_index)\n\n    # Combine content-based recommendations with top-N CF recommendations\n    # For simplicity, let's use the top-N items from CF for the hybrid recommendations\n    cf_top_n = cf_model.get_neighbors(item_index, k=5)  # Get top 5 similar items using CF\n\n    # Combine collaborative filtering and content-based recommendations\n    hybrid_recommendations = list(set(content_based_recommendations).union(set(cf_top_n)))\n    \n    # Evaluate precision and recall\n    true_items = df[df['TransactionNo'] == transaction_no]['Items'].tolist()\n    true_items_set = set(true_items)\n    recommended_items_set = set(hybrid_recommendations)\n\n    precision = len(true_items_set.intersection(recommended_items_set)) / len(recommended_items_set)\n    recall = len(true_items_set.intersection(recommended_items_set)) / len(true_items_set)\n\n    #return precision, recall\n    return hybrid_recommendations\n\n# Example usage\ntransaction_no = 56  # Replace with the transaction number you want to get recommendations for\nrecommendations = hybrid_recommendation(transaction_no)\nprint(recommendations)\n\n#precision, recall = hybrid_recommendation(transaction_no)\n#print(f'Hybrid Recommendation Precision: {precision}')\n#print(f'Hybrid Recommendation Recall: {recall}')\n\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-09-22T16:15:25.732000Z","iopub.execute_input":"2023-09-22T16:15:25.732442Z","iopub.status.idle":"2023-09-22T16:15:35.032255Z","shell.execute_reply.started":"2023-09-22T16:15:25.732411Z","shell.execute_reply":"2023-09-22T16:15:35.030360Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Computing the msd similarity matrix...\nDone computing similarity matrix.\nCollaborative Filtering MAE: 0.35278335479468054\nCollaborative Filtering RMSE: 0.783090321598133\n[0, 2, 4, 5, 6, 'Coffee']\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}